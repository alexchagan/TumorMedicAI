{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c02be-51db-4bf8-a9d2-8e7cac3c02eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23cfa98-9a1f-43d9-bd32-3b0801c02665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e36e860-ffe0-4419-85cd-ecd110e793d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!touch ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19068bd-681c-40bb-acef-2f60e6cbf896",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_token = {\"username\":\"alexchagan\",\"key\":\"bd346664681d63e3d147792e8f1c77d3\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c443ff5f-d4b4-45cc-ae07-8d7047dbd468",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/root/.kaggle/kaggle.json','w') as file:\n",
    "    json.dump(api_token,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5574609c-d665-4f6d-aa72-75c5272043d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee15398e-4823-445f-b786-5bf50b9d63f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a dataset from kaggle\n",
    "\n",
    "!kaggle datasets download -d jakeshbohaju/brain-tumor --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd60f15-092e-4322-9b78-1beee9c37596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('./brain-tumor.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc0ce6-d26b-4b3c-9eec-3aaf27fb4faf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# read csv contiaining names of images and correlating class names into dataframe\n",
    "df = pd.read_csv('./data/Brain Tumor.csv')\n",
    "\n",
    "image_names = df['Image']\n",
    "classes = df['Class']\n",
    "\n",
    "# create a dictionary which points image names to class names\n",
    "name_to_class = dict(zip(image_names, classes))\n",
    "\n",
    "# make directories for different classes\n",
    "if not os.path.exists('./data/tumor'):\n",
    "    os.mkdir('./data/tumor')\n",
    "if not os.path.exists('./data/not_tumor'):\n",
    "    os.mkdir('./data/not_tumor')\n",
    "\n",
    "# iterate over all images and save each image in the right class folder\n",
    "folder = './data/Brain Tumor/Brain Tumor/*.jpg'\n",
    "img_paths = glob.glob(folder)\n",
    "for path in img_paths:\n",
    "    img_name = path.split('/')[-1].split('.')[0]\n",
    "    class_name = name_to_class[img_name]\n",
    "    if class_name == 0:\n",
    "        class_name = 'not_tumor'\n",
    "    else:\n",
    "        class_name = 'tumor'\n",
    "        \n",
    "    raw_img = Image.open(path)\n",
    "    resized_img = raw_img.resize((224,224)) # resize to (244,244)\n",
    "    resized_img.save(f'./data/{class_name}/{img_name}'+'.jpg')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488b5e0a-1ef1-4d2e-b4d6-b37916d3d267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0200c9c-3d1d-4f61-9d40-6544faf010b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "\n",
    "splitfolders.ratio('./data', output=\"output\", seed=1337, ratio=(.9, 0.0,0.1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fec3d0e-c6bb-467d-bf33-4e39dd11b570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "shutil.rmtree('data')\n",
    "shutil.rmtree('output/val')\n",
    "os.rename('output','brain_tumor_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9b4b9c-082f-4f32-a4c1-0ed72c433825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "folder='./brain_tumor_data/*/*/*.jpg'\n",
    "\n",
    "category=[]\n",
    "brain_condition=[]\n",
    "filenames=[]\n",
    "\n",
    "all_files = glob.glob(folder)\n",
    "\n",
    "for filename in all_files:\n",
    "    if 'train' in filename:\n",
    "        if 'not_tumor' in filename:\n",
    "            category.append(\"train\")\n",
    "            filenames.append(filename)\n",
    "            brain_condition.append(\"not_tumor\")\n",
    "        else:\n",
    "            category.append(\"train\")\n",
    "            filenames.append(filename)\n",
    "            brain_condition.append(\"tumor\")\n",
    "    else:\n",
    "        if 'not_tumor' in filename:\n",
    "            category.append(\"test\")\n",
    "            filenames.append(filename)\n",
    "            brain_condition.append(\"not_tumor\")\n",
    "        else:\n",
    "            category.append(\"test\")\n",
    "            filenames.append(filename)\n",
    "            brain_condition.append(\"tumor\") \n",
    "   \n",
    "all_data_df = pd.DataFrame({\"dataset type\": category,\"x-ray result\":brain_condition, \"filename\":filenames})\n",
    "print(all_data_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d72a2f-e5f2-4878-92aa-4fd5cfebeff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "g = sns.catplot(x=\"x-ray result\", col=\"dataset type\", kind=\"count\", palette=\"ch:.150\", data=all_data_df, legend=True)\n",
    "\n",
    "# display height of each patch in the plot\n",
    "for i in range(2):\n",
    "    ax=g.facet_axis(0,i)\n",
    "    for p in ax.patches:\n",
    "        ax.text(p.get_x()+0.3, p.get_height()*1.05, '{0:.0f}'.format(p.get_height()), color='black', rotation='horizontal', size='large' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3e103003-8762-4941-9ef5-c76688c41e33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket:medical-ai-tumor\n",
      "region:eu-central-1\n",
      "roleArn:arn:aws:s3:::medical-ai-tumor\n"
     ]
    }
   ],
   "source": [
    "# define bucket name , region and role\n",
    "\n",
    "bucket = 'medical-ai-tumor'\n",
    "print(\"bucket:{}\".format(bucket))\n",
    "region = 'eu-central-1'\n",
    "print(\"region:{}\".format(region))\n",
    "roleArn='arn:aws:s3:::medical-ai-tumor'\n",
    "print(\"roleArn:{}\".format(roleArn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad50b17-55a1-4216-bbd0-fd711e999768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DEFAULT_S3_BUCKET\"]=bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c0e5a462-794b-47a6-af4d-d2dc3ce5d3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::634002663774:role/service-role/AmazonSageMaker-ExecutionRole-20230126T005057\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e72870c-18b8-4e6f-96fe-5a4f8023027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store data in the bucket in the following directory structure\n",
    "  # |--class a\n",
    "  #       |--abc.jpg\n",
    "  #       |--def.jpg\n",
    "  # |--class b\n",
    "  #       |--ghi.jpg\n",
    "  #       |--jkl.jpg\n",
    "\n",
    "!aws s3 sync ./brain_tumor_data/train s3://${DEFAULT_S3_BUCKET}/brain_tumor_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b1a61b-6dcc-4122-8d8f-4a03822e4ac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the training model\n",
    "\n",
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "model_id, model_version = \"tensorflow-ic-efficientnet-b3-classification-1\", \"*\"\n",
    "training_instance_type = \"ml.p2.xlarge\"\n",
    "\n",
    "# Retrieve the Docker image\n",
    "train_image_uri = image_uris.retrieve(model_id=model_id,model_version=model_version,image_scope=\"training\",instance_type=training_instance_type,region=None,framework=None)\n",
    "\n",
    "# Retrieve the training script\n",
    "train_source_uri = script_uris.retrieve(model_id=model_id, model_version=model_version, script_scope=\"training\")\n",
    "\n",
    "# Retrieve the pretrained model tarball for transfer learning\n",
    "train_model_uri = model_uris.retrieve(model_id=model_id, model_version=model_version, model_scope=\"training\")\n",
    "\n",
    "# Retrieve the default hyper-parameters for fine-tuning the model\n",
    "hyperparameters = hyperparameters.retrieve_default(model_id=model_id, model_version=model_version)\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f4ba1a-505e-4389-afa8-8349c23c3e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_s3_path=f\"s3://{bucket}/brain_tumor_data/\"\n",
    "s3_output_location=f\"s3://{bucket}/models/image_model_effiecentnet\"\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "tf_ic_estimator = Estimator(\n",
    "    role=role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_location,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310236e0-4150-4839-b4f3-ed3f2d3c97e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use S3 path of the training data to launch SageMaker TrainingJob\n",
    "tf_ic_estimator.fit({\"training\": training_dataset_s3_path}, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1702d68c-7dc7-4236-8a4c-5fa1ca5c9448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_job_name = tf_ic_estimator.latest_training_job.job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "52015d10-7021-4a10-b1c7-7df74f71be79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "\n",
    "inference_instance_type = \"ml.p2.xlarge\"\n",
    "\n",
    "# Retrieve the inference docker container uri\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,\n",
    "    image_scope=\"inference\",\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "\n",
    "# Retrieve the inference script uri\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "endpoint_name = 'Image-classifier-Tumor'\n",
    "\n",
    "model_url = 's3://medical-ai-tumor/models/image_model_effiecentnet/sagemaker-jumpstart-2023-02-06-00-36-52-371/output/model.tar.gz'\n",
    "\n",
    "model = Model(image_uri=deploy_image_uri, \n",
    "              model_data=model_url,\n",
    "              entry_point=\"inference.py\",\n",
    "              source_dir=deploy_source_uri,\n",
    "              role=role)\n",
    "\n",
    "# Use the estimator from the previous step to deploy to a SageMaker endpoint\n",
    "finetuned_predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "83de0e70-0a4d-45e3-b614-3e9bd9a5fe00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sagemaker.predictor.Predictor object at 0x7f2ce757e790>\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "predictor=Predictor('Image-classifier-Tumor')\n",
    "print(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "01fd9f65-c606-4ad2-acca-711076b2fcfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "file_name = 'brain_tumor_data/test/not_tumor/Image1038.jpg'\n",
    "\n",
    "with open(file_name, \"rb\") as file:\n",
    "        img = file.read()\n",
    "        \n",
    "query_response = predictor.predict(\n",
    "    img, {\"ContentType\": \"application/x-image\", \"Accept\": \"application/json;verbose\"})\n",
    "pred = literal_eval(query_response.decode('utf-8'))\n",
    "print(type(pred[\"predicted_label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "183d9bfd-d990-4b16-91c0-de7f8717ed70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "file_path='brain_tumor_data/test/*/*.jpg'\n",
    "\n",
    "file_paths=glob.glob(file_path)\n",
    "\n",
    "y_true=[]\n",
    "y_pred=[]\n",
    "\n",
    "def make_pred():\n",
    "    for path in file_paths:\n",
    "        if 'not_tumor' in path:\n",
    "            y_true.append(0)\n",
    "        else:\n",
    "            y_true.append(1)\n",
    "            \n",
    "        with open(path, \"rb\") as file:\n",
    "            img = file.read()\n",
    "        query_response = predictor.predict(\n",
    "            img, {\"ContentType\": \"application/x-image\", \"Accept\": \"application/json;verbose\"})\n",
    "        pred = literal_eval(query_response.decode('utf-8')) # turn byte object into dict object\n",
    "        \n",
    "        if pred[\"predicted_label\"] == \"not_tumor\":\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "\n",
    "\n",
    "make_pred()\n",
    "print(y_true)\n",
    "print(y_pred)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ab35d91e-e882-4fb3-b5ca-a8e4c46cc646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[202,   6],\n",
       "       [ 16, 153]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c73ea26b-5c36-473a-aee6-e9cbd536bf34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       208\n",
      "           1       0.96      0.91      0.93       169\n",
      "\n",
      "    accuracy                           0.94       377\n",
      "   macro avg       0.94      0.94      0.94       377\n",
      "weighted avg       0.94      0.94      0.94       377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce592a-e627-4c19-9ce8-88726d0742f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
